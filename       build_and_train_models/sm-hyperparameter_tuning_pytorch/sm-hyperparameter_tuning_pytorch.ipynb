{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "984a252c",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning using SageMaker PyTorch Container\n",
    "\n",
    "This notebook demonstrates how to use [SageMaker Automatic Model Tuning](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning.html) (hyperparameter optimization) to find the best hyperparameters for training a PyTorch MNIST model.\n",
    "\n",
    "### SageMaker Python SDK V3 APIs used\n",
    "\n",
    "| Package | Class / Utility | Purpose |\n",
    "|---------|----------------|----------|\n",
    "| `sagemaker-train` | `ModelTrainer` | Unified training interface (replaces V2 `PyTorch` Estimator) |\n",
    "| `sagemaker-train` | `HyperparameterTuner` | Automatic hyperparameter optimization |\n",
    "| `sagemaker-train` | `SourceCode`, `InputData`, `Compute` | Structured training configuration |\n",
    "| `sagemaker-core` | `Model`, `EndpointConfig`, `Endpoint` | Low-level resource management for deployment |\n",
    "| `sagemaker-core` | `repack_model()` | Inject inference code into model artifacts |\n",
    "| `sagemaker-core` | `image_uris.retrieve()` | Retrieve SageMaker Deep Learning Container URIs |\n",
    "| `sagemaker-core` | `Session`, `get_execution_role` | Session management and IAM role resolution |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d71a8c4",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid #ff9900; border-radius: 8px; padding: 15px; background-color: #fff3e0; margin-bottom: 10px;\">\n",
    "<strong>\u26a0\ufe0f Compatibility Notice:</strong> This notebook has been tested using <strong>SageMaker Distribution Image 3.7.0</strong> and the <strong>SageMaker Python SDK version 3.4.0</strong>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56249c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U \"sagemaker==3.4.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855e6656",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [Background](#Background)\n",
    "1. [Setup](#Setup)\n",
    "1. [Data](#Data)\n",
    "1. [Train](#Train)\n",
    "1. [Host](#Host)\n",
    "\n",
    "---\n",
    "\n",
    "## Background\n",
    "\n",
    "MNIST is a widely used dataset for handwritten digit classification. It consists of 70,000 labeled 28x28 pixel grayscale images of hand-written digits. The dataset is split into 60,000 training images and 10,000 test images. There are 10 classes (one for each of the 10 digits). This tutorial shows how to train and test an MNIST model on SageMaker using PyTorch, and how to use SageMaker Automatic Model Tuning to find the best hyperparameters.\n",
    "\n",
    "---\n",
    "\n",
    "## Setup\n",
    "\n",
    "We start by creating a `Session` (from `sagemaker.core`) and resolving the IAM execution role. The session manages interactions with S3 and the SageMaker service.\n",
    "\n",
    "- `Session()` \u2014 initializes the SageMaker session with default bucket and region\n",
    "- `get_execution_role()` \u2014 retrieves the IAM role ARN for training and hosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551453b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.metadata import version as pkg_version\n",
    "print(f\"SageMaker SDK version: {pkg_version('sagemaker')}\")\n",
    "\n",
    "from sagemaker.core.helper.session_helper import Session, get_execution_role\n",
    "from sagemaker.core import image_uris\n",
    "\n",
    "sagemaker_session = Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"sagemaker/DEMO-pytorch-mnist\"\n",
    "default_bucket_prefix = sagemaker_session.default_bucket_prefix\n",
    "\n",
    "# If a default bucket prefix is specified, append it to the s3 path\n",
    "if default_bucket_prefix:\n",
    "    prefix = f\"{default_bucket_prefix}/{prefix}\"\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ee7278",
   "metadata": {},
   "source": [
    "## Data\n",
    "### Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb3ecfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import urllib.request\n",
    "\n",
    "local_dir = \"data\"\n",
    "base_url = f\"https://sagemaker-example-files-prod-{region}.s3.amazonaws.com/datasets/image/MNIST/\"\n",
    "files = [\n",
    "    \"t10k-images-idx3-ubyte.gz\",\n",
    "    \"t10k-labels-idx1-ubyte.gz\",\n",
    "    \"train-images-idx3-ubyte.gz\",\n",
    "    \"train-labels-idx1-ubyte.gz\",\n",
    "]\n",
    "os.makedirs(\"data/MNIST/raw\", exist_ok=True)\n",
    "for f in files:\n",
    "    gz_path = f\"data/MNIST/raw/{f}\"\n",
    "    raw_path = gz_path.replace(\".gz\", \"\")\n",
    "    if not os.path.exists(gz_path):\n",
    "        print(f\"Downloading {f}...\")\n",
    "        urllib.request.urlretrieve(base_url + f, gz_path)\n",
    "    # Extract .gz files (torchvision in the container expects uncompressed files)\n",
    "    if not os.path.exists(raw_path):\n",
    "        with gzip.open(gz_path, \"rb\") as f_in:\n",
    "            with open(raw_path, \"wb\") as f_out:\n",
    "                f_out.write(f_in.read())\n",
    "print(\"MNIST data ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa198623",
   "metadata": {},
   "source": [
    "### Uploading the data to S3\n",
    "We use `Session.upload_data()` to upload the dataset to S3. The returned S3 URI is passed as an `InputData` source to the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fff1bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = sagemaker_session.upload_data(path=\"data\", bucket=bucket, key_prefix=prefix)\n",
    "print(\"input spec (in this case, just an S3 path): {}\".format(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef347fc",
   "metadata": {},
   "source": [
    "## Train\n",
    "### Training script\n",
    "The `mnist.py` script provides all the code we need for training and hosting a SageMaker model (`model_fn` function to load a model).\n",
    "The training script is very similar to a training script you might run outside of SageMaker, but you can access useful properties about the training environment through various environment variables, such as:\n",
    "\n",
    "* `SM_MODEL_DIR`: A string representing the path to the directory to write model artifacts to. These artifacts are uploaded to S3 for model hosting.\n",
    "* `SM_NUM_GPUS`: The number of GPUs available in the current container.\n",
    "* `SM_CHANNEL_TRAINING`: A string representing the path to the directory containing data in the 'training' channel.\n",
    "\n",
    "For more information about training environment variables, please visit [SageMaker Containers](https://github.com/aws/sagemaker-containers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fa69c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize mnist.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa77980f",
   "metadata": {},
   "source": [
    "### Set up hyperparameter tuning job\n",
    "*Note, with the default setting below, the hyperparameter tuning job can take about 20 minutes to complete.*\n",
    "\n",
    "We use the V3 `HyperparameterTuner` (from `sagemaker.train.tuner`) together with `ModelTrainer` to run automatic model tuning. The steps are:\n",
    "\n",
    "1. Create a `ModelTrainer` with `SourceCode`, `Compute`, and the training image URI\n",
    "2. Define hyperparameter ranges using `ContinuousParameter`, `CategoricalParameter`, or `IntegerParameter` (from `sagemaker.core.parameter`)\n",
    "3. Define the objective metric and its regex pattern\n",
    "4. Create a `HyperparameterTuner` with the trainer, ranges, metric, and resource budget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6214cd",
   "metadata": {},
   "source": [
    "We define a `ModelTrainer` (from `sagemaker.train`) passing in:\n",
    "- `training_image` \u2014 the container URI retrieved via `image_uris.retrieve()`\n",
    "- `source_code` \u2014 a `SourceCode` config pointing to the local directory and entry script\n",
    "- `compute` \u2014 a `Compute` config specifying instance type and count\n",
    "- `role` \u2014 the IAM execution role\n",
    "- `hyperparameters` \u2014 static hyperparameters (not tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3cc905",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.train import ModelTrainer\n",
    "from sagemaker.train.configs import SourceCode, InputData, Compute\n",
    "\n",
    "training_image = image_uris.retrieve(\n",
    "    framework=\"pytorch\",\n",
    "    region=region,\n",
    "    version=\"2.0.1\",\n",
    "    py_version=\"py310\",\n",
    "    instance_type=\"ml.c5.2xlarge\",\n",
    "    image_scope=\"training\",\n",
    ")\n",
    "\n",
    "trainer = ModelTrainer(\n",
    "    training_image=training_image,\n",
    "    source_code=SourceCode(source_dir=\".\", entry_script=\"mnist.py\"),\n",
    "    compute=Compute(instance_type=\"ml.c5.2xlarge\", instance_count=1),\n",
    "    role=role,\n",
    "    hyperparameters={\"epochs\": \"1\", \"backend\": \"gloo\"},\n",
    "    base_job_name=\"pytorch-mnist-hpo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41063779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test training job\n",
    "\n",
    "trainer.train(\n",
    "    input_data_config=[InputData(channel_name=\"training\", data_source=inputs)],\n",
    "    wait=True,\n",
    "    logs=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fd8508",
   "metadata": {},
   "source": [
    "Once we've defined our `ModelTrainer` we can specify the hyperparameters we'd like to tune and their possible values. We have three different types of hyperparameters.\n",
    "- Categorical parameters need to take one value from a discrete set. We define this by passing the list of possible values to `CategoricalParameter(list)`\n",
    "- Continuous parameters can take any real number value between the minimum and maximum value, defined by `ContinuousParameter(min, max)`\n",
    "- Integer parameters can take any integer value between the minimum and maximum value, defined by `IntegerParameter(min, max)`\n",
    "\n",
    "*Note, if possible, it's almost always best to specify a value as the least restrictive type. For example, tuning learning rate as a continuous value between 0.01 and 0.2 is likely to yield a better result than tuning as a categorical parameter with values 0.01, 0.1, 0.15, or 0.2.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b03a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.core.parameter import ContinuousParameter, CategoricalParameter\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    \"lr\": ContinuousParameter(0.001, 0.1),\n",
    "    \"batch-size\": CategoricalParameter([32, 64, 128, 256, 512]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d8dc06",
   "metadata": {},
   "source": [
    "Next we specify the objective metric that we'd like to tune and its definition, which includes the regular expression (Regex) needed to extract that metric from the CloudWatch logs of the training job. In this case, our script emits average loss value and we will use it as the objective metric. We set `objective_type` to `'Minimize'`, so that hyperparameter tuning seeks to minimize the objective metric when searching for the best hyperparameter setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea9e415",
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_metric_name = \"average test loss\"\n",
    "objective_type = \"Minimize\"\n",
    "metric_definitions = [{\"Name\": \"average test loss\", \"Regex\": \"Test set: Average loss: ([0-9\\\\.]+)\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23596e57",
   "metadata": {},
   "source": [
    "Now, we create a `HyperparameterTuner` (from `sagemaker.train.tuner`), passing in:\n",
    "- The `ModelTrainer` instance\n",
    "- Hyperparameter ranges\n",
    "- Objective metric name and definition\n",
    "- Tuning resource configurations: `max_jobs` (total training jobs) and `max_parallel_jobs` (concurrent jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8974d656",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.train.tuner import HyperparameterTuner\n",
    "\n",
    "# Create a fresh ModelTrainer for the tuner\n",
    "tuner_trainer = ModelTrainer(\n",
    "    training_image=training_image,\n",
    "    source_code=SourceCode(source_dir=\".\", entry_script=\"mnist.py\"),\n",
    "    compute=Compute(instance_type=\"ml.c5.2xlarge\", instance_count=1),\n",
    "    role=role,\n",
    "    hyperparameters={\"epochs\": \"1\", \"backend\": \"gloo\"},\n",
    "    base_job_name=\"pytorch-mnist-hpo\",\n",
    ")\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    tuner_trainer,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions,\n",
    "    max_jobs=9,\n",
    "    max_parallel_jobs=3,\n",
    "    objective_type=objective_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2361157e",
   "metadata": {},
   "source": [
    "### Launch hyperparameter tuning job\n",
    "We start the tuning job by calling `tuner.tune()` with an `InputData` config pointing to our S3 training data. Setting `wait=True` blocks until all training jobs complete.\n",
    "\n",
    "You can monitor progress in the SageMaker console under **Hyperparameter tuning jobs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381f8cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.tune(\n",
    "    inputs=[InputData(channel_name=\"training\", data_source=inputs)],\n",
    "    wait=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ea8a8e",
   "metadata": {},
   "source": [
    "## Host\n",
    "### Create endpoint\n",
    "After tuning completes, we deploy the best model to a real-time endpoint. The steps are:\n",
    "\n",
    "1. **Get best training job** \u2014 `tuner.best_training_job()` returns the name of the job with the best objective metric\n",
    "2. **Retrieve model artifacts** \u2014 `TrainingJob.get()` fetches the job metadata, including the S3 URI of `model.tar.gz`\n",
    "3. **Repack model** \u2014 `repack_model()` (from `sagemaker.core.utils`) injects the inference script into the model archive. The PyTorch serving container expects a `code/` directory inside `model.tar.gz` containing the entry point script\n",
    "4. **Create resources** \u2014 Use `sagemaker-core` resource classes (`Model.create()`, `EndpointConfig.create()`, `Endpoint`) to deploy\n",
    "\n",
    "The `repack_model()` utility handles the full download \u2192 extract \u2192 inject \u2192 re-tar \u2192 upload workflow in a single call, replacing what would otherwise be ~15 lines of manual S3/tarfile code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a97bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import boto3\n",
    "from sagemaker.core.resources import TrainingJob, Model, EndpointConfig, Endpoint\n",
    "from sagemaker.core.shapes import ContainerDefinition, ProductionVariant\n",
    "from sagemaker.core.utils import repack_model\n",
    "\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "sm_runtime = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "# Get best training job\n",
    "best_job_name = tuner.best_training_job()\n",
    "print(f\"Best training job: {best_job_name}\")\n",
    "\n",
    "best_training_job = TrainingJob.get(training_job_name=best_job_name)\n",
    "model_data = best_training_job.model_artifacts.s3_model_artifacts\n",
    "print(f\"Best model artifacts: {model_data}\")\n",
    "\n",
    "inference_image = image_uris.retrieve(\n",
    "    framework=\"pytorch\", region=region, version=\"2.0.1\",\n",
    "    py_version=\"py310\", instance_type=\"ml.m5.xlarge\", image_scope=\"inference\",\n",
    ")\n",
    "\n",
    "# Repack model with inference code using V3 repack_model utility\n",
    "repackaged_s3 = f\"s3://{bucket}/{prefix}/repackaged-model/model.tar.gz\"\n",
    "repack_model(\n",
    "    inference_script=\"mnist.py\",\n",
    "    source_directory=\".\",\n",
    "    dependencies=[],\n",
    "    model_uri=model_data,\n",
    "    repacked_model_uri=repackaged_s3,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "print(f\"Repacked model: {repackaged_s3}\")\n",
    "\n",
    "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_name = f\"pytorch-mnist-hpo-model-{timestamp}\"\n",
    "endpoint_config_name = f\"pytorch-mnist-hpo-epc-{timestamp}\"\n",
    "endpoint_name = f\"pytorch-mnist-hpo-ep-{timestamp}\"\n",
    "\n",
    "sm_model = Model.create(\n",
    "    model_name=model_name,\n",
    "    primary_container=ContainerDefinition(\n",
    "        image=inference_image,\n",
    "        model_data_url=repackaged_s3,\n",
    "        environment={\"SAGEMAKER_PROGRAM\": \"mnist.py\"},\n",
    "    ),\n",
    "    execution_role_arn=role,\n",
    ")\n",
    "print(f\"Model created: {model_name}\")\n",
    "\n",
    "endpoint_config = EndpointConfig.create(\n",
    "    endpoint_config_name=endpoint_config_name,\n",
    "    production_variants=[\n",
    "        ProductionVariant(\n",
    "            variant_name=\"AllTraffic\",\n",
    "            model_name=model_name,\n",
    "            instance_type=\"ml.m5.xlarge\",\n",
    "            initial_instance_count=1,\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "print(f\"EndpointConfig created: {endpoint_config_name}\")\n",
    "\n",
    "sm_client.create_endpoint(EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name)\n",
    "print(f\"Creating endpoint: {endpoint_name} ...\")\n",
    "waiter = sm_client.get_waiter(\"endpoint_in_service\")\n",
    "waiter.wait(EndpointName=endpoint_name, WaiterConfig={\"Delay\": 30, \"MaxAttempts\": 60})\n",
    "print(\"Endpoint in service!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b61890e",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "We can now use this endpoint to classify hand-written digits. We load test images, serialize them with `NumpySerializer` (from `sagemaker.core.serializers`), and invoke the endpoint via `boto3 invoke_endpoint()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e39140a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import io\n",
    "\n",
    "data_dir = \"data/MNIST/raw\"\n",
    "with gzip.open(os.path.join(data_dir, \"t10k-images-idx3-ubyte.gz\"), \"rb\") as f:\n",
    "    images = np.frombuffer(f.read(), np.uint8, offset=16).reshape(-1, 28, 28).astype(np.float32)\n",
    "\n",
    "mask = random.sample(range(len(images)), 16)  # randomly select some of the test images\n",
    "mask = np.array(mask, dtype=np.intp)\n",
    "data = images[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f78bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.core.serializers import NumpySerializer\n",
    "\n",
    "serializer = NumpySerializer()\n",
    "payload = serializer.serialize(np.expand_dims(data, axis=1))\n",
    "\n",
    "response = sm_runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=\"application/x-npy\",\n",
    "    Accept=\"application/x-npy\",\n",
    "    Body=payload,\n",
    ")\n",
    "result = np.load(io.BytesIO(response[\"Body\"].read()), allow_pickle=True)\n",
    "\n",
    "print(\"Raw prediction result:\")\n",
    "print(result)\n",
    "print()\n",
    "\n",
    "labeled_predictions = list(zip(range(10), result[0]))\n",
    "print(\"Labeled predictions: \")\n",
    "print(labeled_predictions)\n",
    "print()\n",
    "\n",
    "labeled_predictions.sort(key=lambda label_and_prob: 1.0 - label_and_prob[1])\n",
    "print(\"Most likely answer: {}\".format(labeled_predictions[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de4e951",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "\n",
    "Delete the endpoint, endpoint configuration, and model to release resources and stop incurring charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9a9c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "sm_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "sm_client.delete_model(ModelName=model_name)\n",
    "print(\"Cleanup complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}